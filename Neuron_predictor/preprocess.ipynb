{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import itertools\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "#from keras import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_data = {}\n",
    "\n",
    "files = sorted(os.listdir('../neuron_logs/train_data'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_to_statistics(activations, labels, debug=False):\n",
    "    sorted_data = []\n",
    "    for i in range(10): #hardcoded MOFO\n",
    "        sorted_data += [[]]\n",
    "    for i, a in zip(labels, activations):\n",
    "        sorted_data[i] += [a]\n",
    "    if debug:\n",
    "        return(sorted_data)\n",
    "    statistics = []\n",
    "    for ar in sorted_data:\n",
    "        curr_stats = stats.describe(ar)\n",
    "        statistics += [curr_stats.mean, curr_stats.variance, curr_stats.skewness, curr_stats.kurtosis, curr_stats.minmax[0],\n",
    "                       curr_stats.minmax[1], curr_stats.nobs]\n",
    "        #print(statistics)\n",
    "    return(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, fin = 10, activations_no = 1000, target = 'usefulness_loss', shuffle = True):\n",
    "    \n",
    "    features, labels = [], []\n",
    "    with open(os.path.join('..', 'neuron_logs', 'train_data', filename), 'r') as f:\n",
    "        neuron_data = json.load(f)\n",
    "        for e in neuron_data.keys():\n",
    "            if e == '0' or int(e) > fin:\n",
    "                continue\n",
    "            for neuron in neuron_data[e]:\n",
    "                if ' ' not in neuron:\n",
    "                    continue\n",
    "                current_data = neuron_data[e][neuron]\n",
    "                important_features = []\n",
    "                important_features += [filename]\n",
    "                important_features += [current_data['depth']]\n",
    "                important_features += [current_data['inverse_depth']]\n",
    "                important_features += [current_data['width']]\n",
    "                # important_features += [current_data['input_weights']]\n",
    "                # important_features += [current_data['output_weights']]\n",
    "                important_features += [current_data['reg_loss_in_layer']]\n",
    "                important_features += current_data['activations'][:activations_no]\n",
    "                important_features += reduce_to_statistics(current_data['activations'], neuron_data[e]['original_labels'])\n",
    "                important_features += [e]\n",
    "                important_features += [current_data[target]]\n",
    "                features += [important_features]\n",
    "                #labels += [current_data[target]]\n",
    "    \n",
    "    return(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file output_20191015-203714.json\n",
      "Opening file output_20191015-215448.json\n",
      "Opening file output_20191015-231129.json\n",
      "Opening file output_20191016-002746.json\n",
      "Opening file output_20191016-014510.json\n",
      "Opening file output_20191016-030245.json\n",
      "Opening file output_20191016-042123.json\n",
      "Opening file output_20191016-053821.json\n",
      "Opening file output_20191016-065412.json\n",
      "Opening file output_20191016-081229.json\n",
      "Opening file output_20191016-093233.json\n",
      "Opening file output_20191016-105014.json\n",
      "Opening file output_20191016-120445.json\n",
      "Opening file output_20191016-132206.json\n",
      "Opening file output_20191016-144056.json\n",
      "Opening file output_20191016-155551.json\n",
      "Opening file output_20191016-170459.json\n",
      "Opening file output_20191016-180151.json\n",
      "Opening file output_20191016-190004.json\n",
      "Opening file output_20191016-200022.json\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "\n",
    "with gzip.open('test_data_2.gz', 'wt', compresslevel=5) as f:\n",
    "    writer = csv.writer(f, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i, filename in enumerate(files[1:]):\n",
    "        print(f'Opening file {filename}')\n",
    "        data = extract_data(filename)\n",
    "        for line in data:\n",
    "            writer.writerow(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
